{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🧢Transformer Model**\n",
    "\n",
    "* **Seq2Seq** 모델과 같이 인코더와 디코더로 구성됨.\n",
    "* **Seq2Seq** 모델에서 사용한 순환 신경망을 사용하지 않고, **Self Attention** 기법을 사용하여 문장에 대한 정보를 추출함.\n",
    "\n",
    "<img src=\"./image/transformer_all.png\" width=\"600\" height=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from word_preprocess import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Self-Attention**\n",
    "\n",
    "* 문장에서 각 단어끼리 얼마나 관계가 있는지를 계산해서 반영하는 방법.\n",
    "  - 문장 : **['딥러닝', '자연어', '처리', '아주', '좋아요']**\n",
    "\n",
    "* **Attension score**\n",
    "  - 각 단어('딥러닝')를 기준으로 다른 단어들과의 관계 값을 계산\n",
    "  - 트렌스포머 모델에서는 단어 벡터끼리 내적 연산을 통해 Attention score를 구함.\n",
    "    - $attention\\_score_{q(딥러닝)\\_k(딥러닝)} = vector_{q(딥러닝)} * vector_{k(딥러닝)} = 25$\n",
    "    - $attention\\_score_{q(딥러닝)\\_k(자연어)} = vector_{q(딥러닝)} * vector_{k(자연어)} = 25$\n",
    "    - $attention\\_score_{q(딥러닝)\\_k(처리)} = vector_{q(딥러닝)} * vector_{k(처리)} = 24.3$\n",
    "    - $attention\\_score_{q(딥러닝)\\_k(아주)} = vector_{q(딥러닝)} * vector_{k(아주)} = 24.3$\n",
    "    - $attention\\_score_{q(딥러닝)\\_k(좋아요)} = vector_{q(딥러닝)} * vector_{k(좋아요)} = 24$\n",
    "\n",
    "* **Attension map**\n",
    "  - 각 단어들의 attention score를 하나의 테이블로 만든 것을 Attention map 이라고 함.\n",
    "  - Attention map에 softmax함수를 취해서, 특정 단어('딥러닝')에 대해 다른 단어들의 연관정도가 확률로 나타남.\n",
    "    - $attention\\;map = [25, 25, 24.3, 24.3, 24]$\n",
    "    - $softmax(attention\\;map) = [0.3, 0.3, 0.15, 0.15, 0.1]$\n",
    "\n",
    "\n",
    "* **Context vector**\n",
    "  - 각 단어 벡터들에 대해서 attention score값을 곱해주고 더해주는 weighted sum 연산을 통해 단어 '딥러닝'의 Context vector를 구해줌.\n",
    "    - $context\\_vector_{q(딥러닝)} = softmax(attention\\_score_{q(딥러닝)\\_k(딥러닝)}*vector_{v(딥러닝)}$\n",
    "    - $\\qquad \\qquad \\qquad \\qquad \\qquad + softmax(attention\\_score_{q(딥러닝)\\_k(자연어)})*vector_{v(자연어)}$\n",
    "    - $\\qquad \\qquad \\qquad \\qquad \\quad + softmax(attention\\_score_{q(딥러닝)\\_k(처리)})*vector_{v(처리)}$\n",
    "    - $\\qquad \\qquad \\qquad \\qquad \\quad + softmax(attention\\_score_{q(딥러닝)\\_k(아주)})*vector_{v(아주)}$\n",
    "    - $\\qquad \\qquad \\qquad \\qquad \\qquad + softmax(attention\\_score_{q(딥러닝)\\_k(좋아요)})*vector_{v(좋아요)}$\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**scaled dot product attention**\n",
    "\n",
    "* **self attention 방식**을 기반으로 구성됨. 내적 어텐션 구조가 중첩된 형태.\n",
    "* **내적 어텐션, 순방향 어텐션 마스크, 멀티 헤드 어텐션**\n",
    "  * $Attention(Q,K,V)=softmax\\left (\\frac{QK^{T}}{\\sqrt{d_{k}}}  \\right )V$\n",
    "  * $One\\; query\\;:\\;Q_{(1\\times n)}, K_{(1\\times n)}, V_{(1\\times n)}, Attention(Q,K,V)_{(1\\times n)},d_{k}=n$\n",
    "  * $All\\; query\\;:\\;Q_{(m\\times n)}, K_{(m\\times n)}, V_{(m\\times n)}, Attention(Q,K,V)_{(m\\times n)},d_{k}=n$\n",
    "\n",
    "* quert와 value를 이용해 내적한 값이 벡터의 차원이 커지면 학습이 잘 안될 수 있기 때문에 벡터의 크기에 반비례하도록 크기를 조정 $d_{k}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask) :\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk/tf.math.sqrt(dk)\n",
    "\n",
    "    if mask is not None :\n",
    "        scaled_attention_logits += (mask * -1e9)\n",
    "    \n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "    output = tf.matmul(attention_weights, v)\n",
    "    return output, attention_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈 **Subsequent Masked Attention(순방향 마스크 어텐션)**\n",
    "- seq2seq 모델은 스텝이 존재해서 각 스텝마다 단어가 입력으로 들어가는 구조이지만\n",
    "- transformer 모델은 전체 문장이 한번에 행렬 형태로 입력되는 구조이며 이런 부분이 문제가 될 수 있다.\n",
    "    - 예를 들어, 문장을 예측하는 과정에서 디코더 부분에 입력이 들어갈 텐데 순환 신경망 구조의 경우 자신보다 앞에 있는 단어만 참고해서 단어를 예측한다.\n",
    "    - 하지만, 트랜스포머의 경우 전체 문장이 들어가기 때문에 위치와 상관없이 모든 단어를 참고해 예측하는 문제가 발생.\n",
    "    - 이러한 문제를 해결하기 위해 자신보다 뒤에 있는 단어들은 참고하지 않게 하는 기법이 **mask**기법이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 8), dtype=float32, numpy=\n",
       "array([[  -0., -100., -100., -100., -100., -100., -100., -100.],\n",
       "       [  -0.,   -0., -100., -100., -100., -100., -100., -100.],\n",
       "       [  -0.,   -0.,   -0., -100., -100., -100., -100., -100.],\n",
       "       [  -0.,   -0.,   -0.,   -0., -100., -100., -100., -100.],\n",
       "       [  -0.,   -0.,   -0.,   -0.,   -0., -100., -100., -100.]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "mask = 1 - tf.linalg.band_part(tf.ones((5, 8)), -1, 0)\n",
    "mask*-100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size) :\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_padding_mask(seq) :\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :] # (batch, 1, 1 ,seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_masks(inp, tar) :\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in Decoder's 2nd attention block\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in Decoder's 1st attention block\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "    \n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Multi-Head Attention**\n",
    "\n",
    "* 여러 개의 Scaled Dot-Product Attention들을 통해 다양한 context를 읽은 뒤 합치는 방식을 Multi-head Attention이라고 함.\n",
    "1. query, key, value에 대한 feature를 head 수 만큼 나눔\n",
    "2. 각각의 head에 대해 Linear Layer를 거침.\n",
    "3. 각각의 Linear Layer 출력값에 대해 Scaled Dot-Product Attention을 구함.\n",
    "4. 합쳐서 Multi-Head Attention 값을 구함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model']\n",
    "        \n",
    "        assert self.d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        \n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "    def split_heads(self, x, batch_size) :\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask) :\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q) # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k) # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v) # (batch_size, seq_len, d_model)\n",
    "        \n",
    "        q = self.split_heads(q, batch_size) # (batch_size, num_head, seq_len, depth)\n",
    "        k = self.split_heads(k, batch_size) # (batch_size, num_head, seq_len, depth)\n",
    "        v = self.split_heads(v, batch_size) # (batch_size, num_head, seq_len, depth)\n",
    "        \n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(q, k, v, mask)   # (batch_size, num_head, seq_len, depth)\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])                # (batch_size, seq_len, num_head, depth) \n",
    "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))     # (batch_size, seq_len, d_model)\n",
    "        output = self.dense(concat_attention)\n",
    "\n",
    "        return output, attention_weights\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Position-wise feed forward network**\n",
    "\n",
    "* transformer model은 self-attention layer에서 출력된 값을 feed forward network를 거침\n",
    "\n",
    "$$\n",
    "FFN(x) = max(0, xW_{1} + b_{1})W_{2} + b_{2}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(**kargs) :\n",
    "    return tf.keras.Sequential([tf.keras.layers.Dense(kargs['dff'], activation='relu'),\n",
    "                                tf.keras.layers.Dense(kargs['d_model'])])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Residual connection**\n",
    "\n",
    "* transformer model은 residual connection을 한 다음, 레이어에 대한 값을 Normalization하는 Layer Normalization을 수행함.\n",
    "\n",
    "**Encoder Layer**\n",
    "\n",
    "* 아래 코드는 Encoder Layer에서 Residual Connection을 구현한 모습.\n",
    "* Transformer 전체 구조의 **Add&Norm**에 해당되는 부분으로 자주 사용된다.\n",
    "```python\n",
    "\n",
    "self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "ffn_output = self.ffn(out1)\n",
    "ffn_output = self.dropout2(ffn_output)\n",
    "out2 = self.layernorm2(out1 + ffn_output)\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Positional-Encoding**\n",
    "\n",
    "* transformer model은 입력 데이터를 순차적으로 제공하는 것이 아니라 한번에 입력해주기 때문에 입력 시퀀스에 대한 정보를 추가로 넣어줘야 함.\n",
    "* **\"Positional Encoding\"** 은 트렌스포머 모델에 입력값의 순서 정보를 입력해주기 위해 사용한 방법.\n",
    "\n",
    "$$\n",
    "PE_{(pos,2i)}=\\sin \\left ( pos/10000^{2i/d_{model}} \\right ) \\\\\n",
    "PE_{(pos,2i+1)}=\\cos \\left ( pos/10000^{2i/d_{model}} \\right )\n",
    "$$\n",
    "\n",
    "* 각 단어를 Embedding 했을 때 embedding된 데이터의 feature 인덱스가 짝수인 경우 $cos$ 함수 할당.\n",
    "* 각 단어를 Embedding 했을 때 embedding된 데이터의 feature 인덱스가 홀수인 경우 $sin$ 함수 할당.\n",
    "\n",
    "* 입력 단어의 순서는 $pos$에 반영 됨\n",
    "* 뒷 부분은 생각 해보자\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model) :\n",
    "    angle_rates = 1 / np.power(10000, (2*i//2)/np.float32(d_model))\n",
    "    return pos * angle_rates\n",
    "\n",
    "def positional_encoding(position, d_model) :\n",
    "    angle_rads = get_angles(pos = np.arange(position)[:, np.newaxis],\n",
    "                            i = np.arange(d_model)[np.newaxis, :],\n",
    "                            d_model = d_model)\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**positional encoding example**\n",
    "\n",
    "* position = 25  : 최대 입력 단어\n",
    "* d_model = 64   : 각 단어 embedding 차원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of pos : (25, 1)\n",
      "shape of i : (1, 64)\n",
      "shape of angle_rads : (25, 64)\n",
      "shape of pos_encoding : (1, 25, 64)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEKCAYAAAD+XoUoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAAsTAAALEwEAmpwYAAAtF0lEQVR4nO3deZwdVZk38N+vt3TS2chKNkiAEECRCCEgMBBQMGTUgCMKKPIKGFHigOIS5TODvvoqrwoMCophEXQE1GExIBJjWMIikBATkpAEYgihs9LZQ9bufuaPW93ep+p2V3X63r7b7/v51KfvU+dU1entdPW556lDM4OIiJSHinw3QEREuo46fRGRMqJOX0SkjKjTFxEpI+r0RUTKiDp9EZEykrNOn+QIkk+RXEpyCcmrg/3fIbmG5IJgm5SrNoiI5BvJu0luJLm4jXKS/CnJFSRfJXl8WtlEksuDsmlZaU+u5umTHAJgiJnNJ9kLwCsAzgPwSQA7zewnObmwiEgBIXk6gJ0Afm1m781QPgnAlwFMAnASgFvM7CSSlQBeB3A2gHoAcwFcZGavdaY9ObvTN7N1ZjY/eL0DwFIAw3J1PRGRQmRmcwBsbqfKZKT+IJiZvQigb3DTPB7ACjNbaWb7ADwQ1O2Uqs6eIAmSIwG8H8BLAE4FMJXkZwHMA3CtmW3JcMwUAFMAoAY8YWBFTWvZoFGDXN2dazZFrrllT6OLtw8Y7uKabv5TH7FznYv379rv4n/U9I5+XqH4mDp/TNPgQ30blix1cTXDZwD6HTvGxesWLnPxtiGHuPgIbnXxotBXcuyYEZFrLFj+touHHzLYxes3bHdxtx61Lm5ujv532Li/ycU9e3Vz8fYtO1x88OC+Ll67tiFyzpEj/Pf5zbfWu/jIw4a4+PV/rHHxMUf47/lrK+oj13jPaP/1WfL6ahcfO8Z/vRct9+XvC5UDwKvhOkf5Oq8u8+XHhcoXxpRnqjM2VGdBB8tTdQ4N1XmrY+VHh8qX+vIkdTpanqmO7d7UYGYDIxU7oKL3cEPjnth6tnvTEgDpFaeb2fQOXm4YgPRfyvpgX6b9J3Xw3BE5G95pvQDZE8AzAP6fmT1EcjCABgAG4HtIDQFd1t45hlfW2tXd//lDO/W+qa78uW/eGznmwWX+D8HMz/vRpOGj+7v4p8//0MVrXvZ/BD556JmRa7Cy0sWvnuCP2fq121385NHjXTywmz8eAC7+xzMu/sGQU1z852/9wsWPVD/i4sN8iE1P3xi5Rv8J17r4x//1NRf/8Kez/DmPH+3i3Tv3Rc65ZcNOF59ymv/lnPngHBdP+6q/Yfnu9XdFznn3Lf77fMmUG1z81/uvd/FZF1zn4vmP/sjF7/9X/3kDwNKZN7n4qLOvdvGbT/7MxaPO+rKL65/25QAwfIKvs27OrS4ecrr/vDY+68sH/Ysvf+e52yLXGHjaVS7e9Lyv0/9UX745VN4vVA4AW1/4uYv7nvKlDpVv+5sv7/MBX56kTkfLM9XZv+BXr5jZuEjFDqioG2jVR50XW2/f/DsTXSu48X2sjeGdPwH4oZk9F8SzAXwDwGEAPmxmVwT7LwEw3sy+HD5HR+T0Tp9kNYAHAfzWzB4CADPbkFZ+B4DHctkGEZEDwYroTVmO1ANI/5dzOIC1AGra2N8puZy9QwB3AVhqZjel7U//n/x8ABnf0RYRyR+CFZWxW5bMAPDZYBbPyQC2mdk6pN64HU1yFMkaABcGdTsll3f6pwK4BMAikguCfd8GcBHJsUgN76wC8IUctkFEpOPIrHXqJO8HMAHAAJL1AK4HUA0AZnY7gMeRmrmzAsAuAJ8LyhpJTgUwE0AlgLvNbEln25OzTj8Yn4q+U5n6BEVEChZJVFbXxFdMwMwuiik3ANE3WVJljyPLfWaXzN4RESk2XTim36XU6YuIhGVxeKfQqNMXEQkhAFaU5qPJiqLTrybdnPbr7CxXvmvZTeFDcPH4oS7+wBd8TsNxB/dy8XtO93N9Bzz6qIv7vXlc5BobX3vexW89tdLFJ9/gk5rerKt28fId0fnuW1nn4oOq/d3Gzq0+YaTnWJ+D0tzoE5R27vNJU0D039ZtoUS0ym7dXbx/rz9HVXX0Dqip0SfD1VT5OtbcFCqvaLccAKor2/+lq8iQ3ObL2y0GkPlNp2zr7DUK5fMoL7rTFxEpHxreEREpIyQqsjR7p9Co0xcRCUmN6etOX0SkPGh4R0SknBAV6vRFRMoENbwjIlI2CKKiSm/kioiUB43p51e/9x2NC597tjW+8gy/GMask6OrMJ7ye7+AyWn7/AInjatfdvFbR5zj4lGXh1aoesSv/AQAm1cudPFrr21z8YS1r7p4yOh+Ln7+xehKTmt3+kSpg2v9D96723e5uHqQT0KzZr8i0vZ9zZFrVIWSrzaFFkWprPHl4VWxantE74CaG/05uocSuJr3+/LqBNmOcclXSc7R2WvEJUYx5ngpVur0RUTKB6Mr45UKdfoiIiHUnb6ISBnRmL6ISHmprCrN7rE0PysRkU4gCSZ5vGkRKs0HRouIdBLJ2C3heSaSXE5yBclpGcq/TnJBsC0m2USyX1C2iuSioGxeNj4v3emLiGRQkYU7fZKVAG4DcDaAegBzSc4ws9da6pjZjwH8OKj/UQBfMbPNaac508waOt2YQFF0+ove2owjPv9Aazz8RD+nfvwNP4gc8/Wn1rr4glu+7uLm0Pz126881MXTPnikiy8/Y3vkGstf8HVWzXvMxXvmzXbxwSf4fILdz78dOeeyhndd3L+/nzO/d9s7Lq4afEToDC+6KNMiKhVVfjGXbbt9bkB4kZTwIiq9Doq+wRWehx+3SEp1JdstB4DqivbrxKyxgmKZQq+5/gWIyNbwzngAK8xsJQCQfADAZACvtVH/IgD3Z+PCbdHwjohISOrRyozdEhgGIP3urj7YF70m2QPARAAPpu02AH8h+QrJKQf22XhFcacvItKlSFTG/SuZMiA01j7dzKannynDMdbGuT4K4PnQ0M6pZraW5CAAs0guM7M5SRrWFnX6IiIZJLyTbzCzce2U1wMYkRYPB7C2jboXIjS0Y2Zrg48bST6M1HBRpzp9De+IiISQqTdy47YE5gIYTXIUyRqkOvYZ0euxD4AzAPwxbV8dyV4trwGcA2BxZz833emLiGTALNwSm1kjyakAZgKoBHC3mS0heWVQ3vJkyPMB/MXM0mdyDAbwcPBGfxWA+8zsic62SZ2+iEgG2ZpVZWaPA3g8tO/2UHwPgHtC+1YCOC4rjUijTl9EJIQkKqtKc/Rbnb6ISAal+hiGouj0mxv3Y9emNa3x4l9e5MrPuvXF8CFY+vRzLq541idC1YS+oU8d6hdEqanyCUg3fmRM5Bq3HDPaxTv/xyd8rX327y4++APvDZ0h2u7Fa30S2EeH93bx3h2bXcx+QyLnSNewa39kX3iRlK27QolV3fyPRWMowaumJkNyVmgRlR6hOpHkrAQLoIQTuMLCC6CEr1GRcbacF/cffKnkTcUtFiMhLN2vWVF0+iIiXaklOasUqdMXEYko3adsqtMXEQljdh64VojU6YuIhBBARcx7SsVKnb6ISFgJ3+nnbCIqyREknyK5lOQSklcH+/uRnEXyjeDjQblqg4jIgcrSUzYLTi6zDxoBXGtmRwM4GcBVJI8BMA3AbDMbDWB2EIuIFJD4VbOKdR2EnHX6ZrbOzOYHr3cAWIrUc6QnA7g3qHYvgPNy1QYRkQORxQeuFZwuGdMnORLA+wG8BGCwma0DUn8YgudEZzpmCoApADB0+Ag8/euvtJbNP2WCqzu3Mpz0FE1ACidjbdvvE3neWeYTpZ7u1dfFdaPeilzjrHE+OWtP6Br1L/qEsJGfvyLUpl9Fzrnw7a0uvmSUH/3av8wnbzX1GuhiVvikqIZQ4hUAVHYLJWft9HWqa/05du/w5d0TJGeF68StnNWcYeWsypg7qY4mVmVanauzdz1Jfu+LtG8oe8U6fBMn550+yZ5IrQRzjZltT/ovUbAQwXQAOHbs8W0tOiAiknVkdMnPUpHTTp9kNVId/m/N7KFg9waSQ4K7/CEANuayDSIiHUUQlSV6p5/L2TsEcBeApWZ2U1rRDACXBq8vRdqiASIiBYFAZQVjt2KUyzv9UwFcAmARyQXBvm8DuAHA70leDmA1gAty2AYRkQ4jULSdepycdfpm9hwyLwoMAB/M1XVFRDqLBKrU6YuIlAeSeiNXRKRcpIZ3SrPTL83PSkSkk7L1Ri7JiSSXk1xBMvIEApITSG4juSDY/jPpsQeiKO709y5fjlVnTGiNH1y2yZUP+/ykyDHDR/d38QVD3nDxmpfXufhXoWSu9Yv9ylur7/P1AeBTX3NrG+PJ7tUuXvXmVhefcuhYF/fLkOT00vqdLu49yq+M1bhwt4+793NxRVWNizMlZ1XX9nTxvr2NLq6q9u1qDCWy9aqN/tiEk6uiyVl+VbHq0C+MNUUTp8IJXOHkqrjkrSS/k3F5I7or+qciferAASGz80YuyUoAtwE4G0A9gLkkZ5jZa6Gqz5rZRw7w2A7Rz7SISEjLPP0s3OmPB7DCzFaa2T4ADyD1KJpcH9smdfoiIhlUkrEbgAEk56VtU0KnGQYg/Xks9cG+sA+QXEjyzyTf08FjO6QohndERLpSBx7D0GBm49o7VYZ94cfKzAdwqJntJDkJwCMARic8tsN0py8iEtIyTz9uS6AewIi0eDiAtekVzGy7me0MXj8OoJrkgCTHHgjd6YuIhGTx2TtzAYwmOQrAGgAXArjYXYs8GMAGMzOS45G6Gd8EYGvcsQdCnb6ISAbZ6PTNrJHkVAAzAVQCuNvMlpC8Mii/HcAnAHyRZCOA3QAuNDMDkPHYzrZJnb6ISEi2pmwCrUM2j4f23Z72+lYAtyY9trOKotPfvqcRM1dsaY2/cc0prvzL3zgncsywXv5T63nxLS4+YvbvfP2XjnPxWy886uJlD0Wnxp79XT8HfuMAP9f/hdCc+3VNPVw8NMN8963vvOviPqcf6uLmRp9vsGWPn7teUe3n6b+zfW/kGlXdQ/P0d/t5+tXdfLsa9/lzdK/JME8/tIhK+E2w6CIq8W8nVcdkRMb9TnbFtPJsXKMQPg/x9MA1EZEyomfviIiUGd3pi4iUiWyO6RcadfoiIiEa0xcRKSe60xcRKR8EY2ePFSt1+iIiIQRQWZo3+ur0RUQiCFRoeCd/ho0Zjh/c9cPW+KkBE1z5mP/6cuSYhnf9YiN3XPADF192/jdcfPHg1S6+9U2fjPXi0mci1/jgyz6B69DTD3HxY/+9yMWLNvrEqxF9ukXOubNho4urDznSxda8zMVbQ8lZVaHFYDbuiCZnVdfWunjvnv0u7juwzsXN+33iVffq6OIv4UVQaivbT87qFlMOABUxq3bELeoRd3yqTvvlcYusJJGNc0jXSt3pl+b3rSg6fRGRrpbkpqEYqdMXEQnRmL6ISBkhiaoEz4cqRur0RUQy0J2+iEiZIDSmLyJSPpSRKyJSPnSnLyJSZjSmn0fLd1bhzGcHtMZLn77dlV82+9nIMTWhf81+s+05Fy/7V79S1o0fGePiP70wzsXv/PmOyDXqZ8x08SEfPtHFTb/xyVkvrtrs4o+O7hc55+4t611ccfBJkTrp1u30yVdVtT6xauP2PZFjutVWu3h/KMGrW2jlrKZ9PtGtV4YVv8IrZ3WriiZwpatO8BsVrhNO4KqIWVMqyY1aqdzMlepdab6QTLS6W8JzTQRwC1Lr3N5pZjeEyj8N4JtBuBPAF81sYVC2CsAOAE0AGs3Md0wHoCg6fRGRrpQa3snCechKALcBOBtAPYC5JGeYWXrK/5sAzjCzLSTPBTAdQPrd3plm1tD51qSo0xcRySBLj2EYD2CFma0EAJIPAJgMoLXTN7MX0uq/CGB4Ni7cltLMPhAR6YSWN3LjNgADSM5L26aETjUMwNtpcX2wry2XA/hzWmwA/kLylQznPiC60xcRCSOQcEi/IWacPdO/C5axInkmUp3+aWm7TzWztSQHAZhFcpmZzUnUsjbk7E6f5N0kN5JcnLbvOyTXkFwQbJNydX0RkQPVsohK3JZAPYARafFwAGsj1yPfB+BOAJPNbFPLfjNbG3zcCOBhpIaLOiWXwzv3AJiYYf/NZjY22B7P4fVFRA5IB4Z34swFMJrkKJI1AC4EMMNdizwEwEMALjGz19P215Hs1fIawDkAFqOTcja8Y2ZzSI7M1flFRHIm+fBOu8yskeRUADORmrJ5t5ktIXllUH47gP8E0B/Az4O1F1qmZg4G8HCwrwrAfWb2RGfblI8x/akkPwtgHoBrzWxLpkrBmxapNy5qemLeH+5vLes5eKSrO7KHn3cOABv2Nvp4sR8Ge3zPThf/rHq2iy8/9xMuXvXD6E/Aij+/4eJR105zcc+qe1z8tzf8rKvL3jskcs69c/2Xo/GgES5mhZ//vi60SEp1954u3rw9uohKTXf/bd+51c/l7xmahx+egx8uBzIsklLlv17NofLwv8aZFlGJmz0R/qWMzuPvvLhpeyWaqV/2spmRG4xoPB7ad3va6ysAXJHhuJUAjgvv76yunr3zCwCHAxgLYB2AG9uqaGbTzWycmY1jVW1b1UREcoKM34pRl97pm9mGltck7wDwWFdeX0QkqbiM72LVpZ0+ySFmti4Iz0cW3pQQEck2Ijtj+oUoZ50+yfsBTEAqeaEewPUAJpAci9Q81VUAvpCr64uIHLAiHr6Jk8vZOxdl2H1Xrq4nIpItBEt2eCfRPzAkP07yDZLbSG4nuYPk9lw3TkQkX8r9jdwfAfiomS3NZWNERApFqU7HTdrpb1CHLyLlgsjaUzYLTtJOfx7J3wF4BEBrto+ZPZSLRoUNHX4wrr7pm63xCcP6uPJTVw2NHFP/qF/g5K71foGThtfnunjej5a5+OInr3LxE32juQIL1vsErxMHHOXbHUpiemL1NhcPeN8RkXM2zlnn4u3w162s6e7i1Vt2ubiml1+YZfdOn1gFAN26+2S2LRv8SF3fHjUubgolZ3WviS6QYs3NLq4NJWdZUyg5K8EiKnG/c3FnYIJf2q6YoBF3x1goXUuJ9nEHrFS/Hkk7/d4AdiH17IcWhtTzIkRESk6JzthM1umb2edy3RARkUKReqO2NG/1k87eGU7y4eBRyRtIPkgyp6u7iIjkUwXjt2KU9D+YXyH1ONChSK368miwT0SkJJXqlM2knf5AM/uVmTUG2z0ABuawXSIiedMyeyduK0ZJO/0Gkp8hWRlsnwGwKfYoEZFilGBop9SHdy4D8EkA65F6JPIngn0iIiWJCbZilHT2zmoAH8txW0RECkJqEZV8tyI32u30SX7DzH5E8mfIsIK7mf17zlqWpt+2dbjg8e+1xo3v7nblt33qh5FjLv3+p1z8+RdWu/jWWza7eNaTz7h4/PP3ufjYiYdHrjHnvxe5+G/1O1x8dH+fSLVljV8PufbfooviWHO9ize+61cAC6+MVb/Ffy1qetS5eM+uaHJW34G+TtNef46e3UIrZ+3356irjiZnhVfX6lbZ/spYSRaVjnu0bdzKRkl+aeOm5WUjAUyKU6l+b+N+81oevTAPwCsZNhGRktNyp5+NMX2SE0kuJ7mC5LQM5ST506D8VZLHJz32QLR7p29mjwYvd5nZH0INvSAbDRARKTzZmZ1DshLAbQDOBlAPYC7JGWb2Wlq1cwGMDraTkFpW9qSEx3ZY0jdyv5Vwn4hI8UswRz/h34TxAFaY2Uoz2wfgAQCTQ3UmA/i1pbwIoC/JIQmP7bC4Mf1zAUwCMIzkT9OKegNozHyUiEhxoxlokbcxMxlAcl5aPN3MpqfFwwC8nRbXI3U3j5g6wxIe22Fxs3fWIjWe/zH4MfwdAL7S2YuLiBQsa46vAzSY2bh2yjP9PxD+a9JWnSTHdljcmP5CAAtJ/tbMdGcvImWDyTr9OPUARqTFw5G6mU5SpybBsR0WN7zzezP7JIC/k0z/C0MAZmbv62wDREQKjwGhacYHaC6A0SRHAVgD4EIAF4fqzAAwleQDSA3fbDOzdSTfSXBsh8UN71wdfPxIZy/UGes27MANP3qmzfIHlkWf/fbgh85y8dOXHebi5yed4eJ3/nyHi5f+/HcuPvrKT0QvHJqnP2ORXwDlSycc7OJ33/G5AhUjz4yeE39y0Ztb/Rz66rreLn6r4V0X14YWQNm7O/oPWo/QIiqNe/xiMH17+PLwHPwemebph+fhxyySUlPly8Pz+IH4lYtiF1lJ8EZb3LS7QkjQictHkBwwSzq8E3MaayQ5FcBMAJUA7jazJSSvDMpvB/A4Uu+drkBq3ZLPtXdsZ9sUN7zT0os1ANhtZs0kjwRwFIA/d/biIiKFKkvDOzCzx5Hq2NP33Z722gBcFT6urWM7K+mUzTkAakkOAzAbqb9E92SzISIiBcWa47cilLTTp5ntAvBxAD8zs/MBHJO7ZomI5JOp0yf5AQCfxj8HnZOurysiUlwMJdvpJ+24r0EqA/fh4E2IwwA8lbNWiYjklYFNpTlLPemjlZ8B8AzJXiR7mtlKAF3yhE0Rkbwo0jv5OEkXRj+W5N8BLAbwGslXSL4nt00TEckTs2RbEUo6vPNLAF81s6cAgOQEAHcAOCU3zRIRybMSvdNP2unXtXT4AGBmT5Osa++AbDp4cE988zP/0hq/9fQKV35f4/7IMa88+HsXL1/0totvu/l+F8+6rpuLX3zaJ1Id89uLItcYWvtjFz+0aL2Lh53mJzjtua/Bxbv7DI+cs7LGL7zyj82h5Kvefj367dv2urh7L5+ctXmdX9gFAPr39HUa9/kEsD6R5Cz/9e2eITnLmnxyVW1V+4uoJHlsbTgxqqPnSDpLoRwov6vjsjVPv9Ak7fRXkvwPAL8J4s8AeDM3TRIRybfsZOQWoo4sjD4QwEPBNgBBqrCISMkxA5ob47ciFPfAtVoAVwI4AsAiANeaWXQsRUSkhBDlO7xzL4D9AJ5Fakmvo5Gasy8iUtqay7PTP8bMjgUAkncBeDn3TRIRybfinZIZJ25Mv3Uop6OLqJC8m+RGkovT9vUjOYvkG8HHgzrYXhGR3CvhxzDEdfrHkdwebDsAvK/lNcntMcfeA2BiaN80ALPNbDRST+ucdkCtFhHJKQObG2O3YhT3PP3ohOyEzGwOyZGh3ZMBTAhe3wvgaQDfPNBriIjkTJHeycfp6idlDm5ZmCVYDmxQWxVJTgEwBQAOGjwUD0/+TmvZpdcPcXW/8oJPpAKAW2950MW/e3CWi6+79A8uPmvykS6+LbQq1qzVuyLXOH5QDxf/fIVvR59/P83Fzb/2q2Kt3hadCFVT18fFy0LJVbV9/IjYzm0+sarvQJ8zt35FdEnNfnU+Ea15v18Zq3c3/2ORZOWscOJUt8r27xcqE0wWjk2+il05Kz4jKa5G3DmSrKylvKgiZFlbLrHgFGzSoplNN7NxZjaurm+/fDdHRMqMNTfHbsWoqzv9DSSHAEDwcWMXX19EJIHgTj9u66Qkk1tIjiD5FMmlJJeQvDqt7Dsk15BcEGyT4q7Z1Z3+DACXBq8vBfDHLr6+iEg8Q5d0+kg2uaURqcTYowGcDOAqkukP9rrZzMYGW+x6ujnr9EneD+BvAMaQrCd5OYAbAJxN8g0AZwexiEhBMTPY/v2xWxZMRmpSC4KP52Voyzozmx+83gFgKYBhB3rBnL2Ra2bRx1KmfDBX1xQRyY7Eb+QOIDkvLZ5uZtM7cKHEk1sAIJgR+X4AL6XtnkryswDmIfUfwZb2zqF1bkVEwswiM9La0GBm49qrQPKvAA7OUHRdR5pEsieABwFcY2YteVK/APA9pAakvgfgRqQekNkmdfoiIplkaXaOmX2orTKSG0gOCe7y25zcQrIaqQ7/t2b2UNq5N6TVuQPAY3HtKdgpmyIi+ZO604/bsiB2cgtTySJ3AVhqZjeFytKTls5HaknbdhXFnf6at9fjW9f88z3fn53wYVe+/HPR9Jd9V53v4m0z73Tx377ph91O/80PXFxz3xUu/uWzKyPX+Mk5h7t4+7LXfYUxX3UhK55w8aKN0VWtuvUZ4OLX1/qnXfTsW+vi3Tt84tTIw3xOw/5d2yLXGNTbJ2c1hVbO6hlOzgr9cIdXxcqkpsp/T+JWvcr0C1QZm3zVfnmSxKkkdXKtQstaFZ6W2Tu5dwOA3wcTXVYDuAAASA4FcKeZTQJwKoBLACwiuSA47tvBTJ0fkRwbtHgVgC/EXbAoOn0RkS4VzN7J/WVsEzJMbjGztQAmBa+fQxuJ3WZ2SUevqU5fRCSidB/DoE5fRCSshJ+9o05fRCSDYn22Thx1+iIiEbrTFxEpG2YGa8z9G7n5oE5fRCSs66Zsdrmi6PR79O2HY//twtZ4wR8fcuW/+dfZkWO+P/8BFz8/zi+8MmP+ehcP6O8zqU88qLuLH5m3JnKNQ88728V7r5vr4vrmXi4OL5Ayf/XWyDnrBh7i4m2b/OItPfv4dm1eu8nFQ/qOcvH+3Tsj1+hXV+Pi5tAdTc8a/2NhTf6HP8kiKtUxE+DjygGgMqZO3CIr2Zj9HrtQSxaukQ2a6p9tGt4RESkfFr3ZKRXq9EVEIixrz94pNOr0RUQy0fCOiEiZMIu811Uq1OmLiISZwZo0vCMiUhbMoE5fRKR8mB7DICJSNnSnn19jejfimTO3tsbXH3eVK1/4sccjx8w5368lEF4k5eGxfpGUbz/6mot/cv5RLm5Y9mLkGhUnhxdJme/il9f4BVC69x/q4lfe3Bw5Z58BPVy8Y7Nf4GT4CJ/gtWKHP8fwUFJZeIEUADioe7Wv0+gXYulV45OvwolXtdXRRVTCdaoq4hZRiZwiorOLpCRZIIVdkNWkRVKKj5mhaZ/eyBURKRsa3hERKReavSMiUl66otMn2Q/A7wCMRGqN20+a2ZYM9VYB2AGgCUCjmY3ryPHp4le4FhEpM2ap2TtxWxZMAzDbzEYDmB3EbTnTzMa2dPgHcDwAdfoiIhk1NzXHblkwGcC9wet7AZyX6+M1vCMiEtZsaN7XmKTmAJLz0uLpZja9A1cabGbrAMDM1pEc1EY9A/AXkgbgl2nXSHp8K3X6IiIhhsSzdxpCwy0RJP8K4OAMRdd1oEmnmtnaoFOfRXKZmc3pwPGt1OmLiIRlcfaOmX2orTKSG0gOCe7ShwDY2MY51gYfN5J8GMB4AHMAJDo+XVF0+muW1+M/zvh6a3z9/V/y5VNOiBxz4+3zXPxO89EunnjYQS7+3OwFLj78G5e7eO8VD0ausWxPnYu7HzTYxbOW+q9/n6F+VatN63dEztl3oD9nw1vrXHzYwCNcPOfdbS4e0qfWxU379kSucVCtT85q3u+Ts/rUhlbOCiVW1STIrIpbGStuVSyg8ytjJUm8KoaVsZTblR9dNGVzBoBLAdwQfPxjuALJOgAVZrYjeH0OgP+b9PgwvZErIhJmQHNzc+yWBTcAOJvkGwDODmKQHEqy5VEDgwE8R3IhgJcB/MnMnmjv+PYUxZ2+iEhXMnRNcpaZbQLwwQz71wKYFLxeCeC4jhzfHnX6IiJhZmjer2fviIiUBz1lM7vaSikWESkMevZOLpxpZg15vL6ISEZmyFbGbcHR8I6ISIRWzsq2tlKKW5GcAmAKAAyqqsGHDv/nvPrvX/wLV/ey+gWRC5z4uxNdfN0vX3Lxwh9e7OKG78918dpRl7i4uu6vkWv8fuFaF/c55BgXv7r8HRcPCi2AUv/6+sg5x4/1C60sftKfY/Tgni5u3POuv0ZdNxc3hebgA0C/0CIqkUVSqiraLa/JMLk9bhGVsCSLqMTVycoiKvFVYq7R+Un0modfgJqB5n1N8fWKUL46/diU4uAPwXQAOLJ7neWjkSJSngxWssM7eUnOSk8pBtCSUiwiUhgMsGaL3YpRl3f6JOtI9mp5jVRK8eKuboeISHuamyx2K0b5GN4ZDODh4LkoVQDuS0spFhHJO9M8/expL6VYRKQgmMGK9E4+jqZsioiEGdCk2TsiIuXBADQX6Ru1cdTpi4iEaXgnv7qNGYNRs55ujVeP8YlX534nmji18I4rXPzF7z/q4obv/dTF1Tf/h4unv/S2iwcc6a8JADNf9nWGH+lXRAsnX314ok/eWv78y5Fzvv+QU1z8wI4tLh7Rp7uLG/fudvHguhoXNzdGk7N6dat0cTixqlsoKyq6iEr8pK/qmCpxyVtAfHJV3EIs2ch5UvJV+SrVefpF0emLiHSl1Owd3emLiJQHdfoiImXEDE37S3P2jtbIFREJMXRNRi7JfiRnkXwj+HhQhjpjSC5I27aTvCYo+w7JNWllk+KuqU5fRCTMUouoxG1ZMA3AbDMbDWB2EIeaYsvNbKyZjQVwAoBdSD2zrMXNLeVm9nj4+DB1+iIiGViTxW5ZMBnAvcHrewGcF1P/gwD+YWZvHegF1emLiISkVs7qkgeuDTazdalr2joAg2LqXwjg/tC+qSRfJXl3puGhMHX6IiJhwRu5cRuAASTnpW1Twqci+VeSizNskzvSJJI1AD4G4A9pu38B4HAAYwGsA3Bj3HmKYvbO0jc3YPwlN7fG7/z9d678i+fdEjnmhWv+v4t7DfGLc33lkSUuHjn+LBc/PGuFi48ad2jkGoueedXFl/2fCS6+7clnXPwvR5zu4vu3RZcIHjOgzsX7d+908SF9al3ctM8nZ/Wt9d/ScGIVAPSobn9lrO4xmVU1CZa9il05K0FyVmeTr5IkVnU2+UqJVyUq+ZTNBjMb1+6pzD7UVhnJDSSHmNk6kkMAbGznVOcCmG9mG9LO3fqa5B0AHotrsO70RURCDOiqN3JnALg0eH0pgD+2U/cihIZ2gj8ULc5HgrVJiuJOX0SkSwVj+l3gBgC/J3k5gNUALgAAkkMB3Glmk4K4B4CzAXwhdPyPSI5NtRirMpRHqNMXEYnomgeumdkmpGbkhPevBTApLd4FoH+Gepd09Jrq9EVEQsyAZtNjGEREyoIB2Kfn6YuIlI8m3emLiJQHA1CiD9ksjk6/oqoaPfoPa43PeGCzKz/uvAsjx3zhxjkunnTxh138xB+ecvG3vvZxF3/3+rtc/P3Lvhy5xqd/4/MFJh39SRf/ZMsGF58wtLeL9727LXLOkX3bn4ffv3v78/D7dGt/Dj4A1MXMw6+NmYefZJ5+dUydBKdAZcwk+Lg59knm0MfV0Tz88mSmO30RkbKiO30RkTJhMN3pi4iUi9TsnXy3IjfU6YuIhGhMX0SkzGhMX0SkTKSmbJZmr69OX0QkRPP0RUTKiJkew5BXxx7aD8/feXFr3PuUq1z59hduixwTrnPHzb5O7xt/7uIvjRvq4mlb1rv43MP7Rq7RuMcvcHL84B4ubm7c5+LD+lS7OFPi1NC69r8l/WvbT6zqXRO/REJdVfsZR3HJWd0SrMJQHZPUFNMEAEAF2v+liytngn/P4+p0trxYrpGNcxTKNbJFwzsiImXCAJTojE11+iIiUUrOEhEpG3ojV0SkjGjKpohIGSnl2TsJ5mFkH8mJJJeTXEFyWj7aICLSniaL34pRl9/pk6wEcBtSK7vXA5hLcoaZvdbVbRERyaSUh3fycac/HsAKM1tpZvsAPABgch7aISKSUcsbuaV4p0/r4r9mJD8BYKKZXRHElwA4ycymhupNATAlCN8LYHGXNvTADADQkO9GJKB2Zk8xtBEor3YeamYDO3MCkk8EbYnTYGYTO3OtrpaPN3Iz5WJG/vKY2XQA0wGA5DwzG5frhnWW2pldxdDOYmgjoHZ2VLF15B2Rj+GdegAj0uLhANbmoR0iImUnH53+XACjSY4iWQPgQgAz8tAOEZGy0+XDO2bWSHIqgJkAKgHcbWZLYg6bnvuWZYXamV3F0M5iaCOgdkqgy9/IFRGR/MlLcpaIiOSHOn0RkTJS0J1+IT+ugeTdJDeSXJy2rx/JWSTfCD4elOc2jiD5FMmlJJeQvLpA21lL8mWSC4N2frcQ2xm0qZLk30k+VqhtBACSq0guIrmA5LxgX0G1lWRfkv9DclnwM/qBQmtjKSrYTj/tcQ3nAjgGwEUkj8lvq5x7AITn8k4DMNvMRgOYHcT51AjgWjM7GsDJAK4KvoaF1s69AM4ys+MAjAUwkeTJKLx2AsDVAJamxYXYxhZnmtnYtHnvhdbWWwA8YWZHATgOqa9robWx9JhZQW4APgBgZlr8LQDfyne7Qm0cCWBxWrwcwJDg9RAAy/PdxlB7/4jUM48Ktp0AegCYD+CkQmsnUjklswGcBeCxQv6eA1gFYEBoX8G0FUBvAG8imExSiG0s1a1g7/QBDAPwdlpcH+wrZIPNbB0ABB8H5bk9rUiOBPB+AC+hANsZDJssALARwCwzK8R2/heAb8CvpFdobWxhAP5C8pXgkSZAYbX1MADvAPhVMFx2J8m6AmtjSSrkTj/R4xokHsmeAB4EcI2Zbc93ezIxsyYzG4vU3fR4ku/Nc5Mckh8BsNHMXsl3WxI61cyOR2p49CqSp+e7QSFVAI4H8Aszez+Ad6GhnC5RyJ1+MT6uYQPJIQAQfNyY5/aAZDVSHf5vzeyhYHfBtbOFmW0F8DRS75cUUjtPBfAxkquQejLsWST/G4XVxlZmtjb4uBHAw0g93baQ2loPoD74jw4A/gepPwKF1MaSVMidfjE+rmEGgEuD15ciNYaeNyQJ4C4AS83sprSiQmvnQJJ9g9fdAXwIwDIUUDvN7FtmNtzMRiL1s/ikmX0GBdTGFiTrSPZqeQ3gHKSeUlswbTWz9QDeJjkm2PVBAK+hgNpYsvL9pkJ7G4BJAF4H8A8A1+W7PaG23Q9gHYD9SN21XA6gP1Jv9L0RfOyX5zaehtSQ2KsAFgTbpAJs5/sA/D1o52IA/xnsL6h2prV3Av75Rm7BtRGp8fKFwbak5Xen0NqK1EytecH3/REABxVaG0tx02MYRETKSCEP74iISJap0xcRKSPq9EVEyog6fRGRMqJOX0SkjKjTl7wj2RQ8DXJJ8KTNr5I84J9Nkt9Oez0y/UmoIuVOnb4Ugt2Wehrke5B6INwkANd34nzfjq8iUp7U6UtBsdRjA6YAmMqUSpI/JjmX5KskvwAAJCeQnEPyYZKvkbydZAXJGwB0D/5z+G1w2kqSdwT/SfwlyPoVKUvq9KXgmNlKpH42ByGV6bzNzE4EcCKAz5McFVQdD+BaAMcCOBzAx81sGv75n8Ong3qjAdwW/CexFcC/ddknI1Jg1OlLoWp5yuo5AD4bPHb5JaTS9EcHZS+b2Uoza0LqsRintXGuN81sQfD6FaTWQRApS1X5boBIGMnDADQh9YRFAviymc0M1ZmA6KO223qmyN60100ANLwjZUt3+lJQSA4EcDuAWy31YKiZAL4YPCIaJI8MnhwJpJ67PyqY6fMpAM8F+/e31BcRT3f6Ugi6B8M31Uit6/sbAC2Pgr4TqeGY+cGjot8BcF5Q9jcANyA1pj8HqefGA8B0AK+SnA/gutw3X6R46CmbUpSC4Z2vmdlH8twUkaKi4R0RkTKiO30RkTKiO30RkTKiTl9EpIyo0xcRKSPq9EVEyog6fRGRMvK/lmGeRmsxRlUAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "position = 25\n",
    "d_model = 64\n",
    "pos = np.arange(position)[:, np.newaxis]\n",
    "i = np.arange(d_model)[np.newaxis, :]\n",
    "angle_rads = get_angles(pos, i, d_model)\n",
    "pos_encoding = positional_encoding(position, d_model)\n",
    "\n",
    "print(f'shape of pos : {pos.shape}')\n",
    "print(f'shape of i : {i.shape}')\n",
    "print(f'shape of angle_rads : {angle_rads.shape}')\n",
    "print(f'shape of pos_encoding : {pos_encoding.shape}')\n",
    "\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 64))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🧢Encoder**\n",
    "\n",
    "## 🌈**EnocderLayer**\n",
    "\n",
    "* **🌟Multi-Head Attention**\n",
    "* **🌟position wise feed-foward network**\n",
    "* **🌟Layer Normalization**\n",
    "* **🌟Dropout**\n",
    "* **🌟Residual Network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EnocderLayer(tf.keras.layers.Layer) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(EnocderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    def call(self, x, mask) :\n",
    "        attn_output, _ = self.mha(x, x, x, mask)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)\n",
    "\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)\n",
    "        return out2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Encoder**\n",
    "<img src=\"./image/transformer_all.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(Encoder, self).__init__()\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "        # (1) Input Embedding\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
    "        \n",
    "        # (2) Positional Encoding\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
    "        \n",
    "        # (3) Dropout after positional encoding\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "        # (4) Encoder Layers\n",
    "        self.enc_layers = [EnocderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "    \n",
    "    def call(self, x, mask) :\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        # Input Embedding, Positional Encoding, Dropout\n",
    "        x = self.embedding(x)                                   # (1)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))    # 각 가중치에 대해 sqrt(d_model) 만큼 값을 곱함. -> 각 워드 임베딩에 대해 스케일을 맞추기 위한 과정.\n",
    "        x += self.pos_encoding[:, :seq_len, :]                  # (2)\n",
    "        x = self.dropout(x)                                     # (3)\n",
    "\n",
    "        # (4) xN Encoder Layer\n",
    "        for i in range(self.num_layers) :\n",
    "            x = self.enc_layers[i](x, mask)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🧢Decoder**\n",
    "\n",
    "<img src=\"./image/transformer_all.png\" width=\"600\" height=\"600\">\n",
    "\n",
    "## 🌈**DecoderLayer**\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **🌟Masked Multi-Head Attention**\n",
    "  - 디코더의 입력 사이의 관계를 계산하는 self attention 구조\n",
    "  - 예측해야 하는 디코더에서 특정 단어 이후의 단어를 참고하지 않도록 Mask 설정을 추가\n",
    "* **🌟Multi-Head Attention**\n",
    "  - 인코더와 디코더의 관계를 구하는 attention 구조\n",
    "* **🌟position wise feed-foward network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        # Masked Multi-Head Attention\n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        # Multi-Head Attention\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        # Position wise feed forward network\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask) :\n",
    "        # Masked Multi-Head Attetion\n",
    "        # value : Decoder's Input vector\n",
    "        # key   : Decoder's Input vector\n",
    "        # query : Decoder's Input vector\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)    # Subsequent Masked Multi-Head Attention\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "        # Multi-Head Attetion\n",
    "        # value : Context Vector from Encoder\n",
    "        # key   : Context Vetor from Encoder\n",
    "        # query : Context Vector from Decoder's Masked Multi-Head Attenstion's \n",
    "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)    \n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm1(attn2 + out1)\n",
    "\n",
    "        # Position Wise Feed Foward Network\n",
    "        ffn_output = self.ffn(out2)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output + out2)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🌈**Decoder**\n",
    "\n",
    "<img src=\"./image/transformer_all.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer) :\n",
    "    def __init__(self, **kargs) : \n",
    "        super(Decoder, self).__init__()\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "        # (1) Output Embedding\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model)\n",
    "\n",
    "        # (2) Positional Encoding\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)  \n",
    "\n",
    "        # (3) Dropout\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "        # (4) xN Decoder Layer\n",
    "        self.dec_layers = [DecoderLayer(**kargs) for _ in range(self.num_layers)]\n",
    "        \n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask) :\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "        # Embedding, Positional Encoding, Dropout\n",
    "        x = self.embedding(x)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # xN Decoder Layer\n",
    "        for i in range(self.num_layers) :\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        return x, attention_weights"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **🧢Transformer 구현**\n",
    "\n",
    "<img src=\"./image/transformer_all.png\" width=\"400\" height=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model) :\n",
    "    def __init__(self, **kargs) :\n",
    "        super(Transformer, self).__init__()\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "\n",
    "    def call(self, x) :\n",
    "        inp, tar = x\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "\n",
    "        dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "        \n",
    "        final_output = self.final_layer(dec_output)\n",
    "        return final_output\n",
    "        \n",
    "    def inference(self, x) :\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], 0)\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "\n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE) :\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, -1).numpy()\n",
    "            pred_token = outputs[0][-1]\n",
    "            if pred_token == self.end_token_idx :\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        \n",
    "        return predict_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = os.path.join(os.getcwd(), 'data')\n",
    "DATA_OUT_PATH = os.path.join(os.getcwd(), 'result', 'transformer_kor')\n",
    "TRAIN_INPUTS = os.path.join(DATA_IN_PATH, 'train_inputs.npy')\n",
    "TRAIN_OUTPUTS = os.path.join(DATA_IN_PATH, 'train_outputs.npy')\n",
    "TRAIN_TARGETS = os.path.join(DATA_IN_PATH, 'train_targets.npy')\n",
    "DATA_CONFIGS = os.path.join(DATA_IN_PATH, 'data_configs.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_inputs = np.load(open(TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(TRAIN_OUTPUTS, 'rb'))\n",
    "index_targets = np.load(open(TRAIN_TARGETS, 'rb'))\n",
    "prepro_configs = json.load(open(DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "model_name = 'transformer'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 64\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 1\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 4,\n",
    "         'd_model': 512,\n",
    "         'num_heads': 8,\n",
    "         'dff': 2048,\n",
    "         'input_vocab_size': vocab_size,\n",
    "         'target_vocab_size': vocab_size,\n",
    "         'maximum_position_encoding': MAX_SEQUENCE,\n",
    "         'end_token_idx': char2idx[end_index],\n",
    "         'rate': 0.1\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred) :\n",
    "    mask = tf.math.not_equal(real, 0)\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_*=mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred) :\n",
    "    mask = tf.math.not_equal(real, 0)\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask\n",
    "    acc = train_accuracy(real, pred)\n",
    "    return tf.reduce_mean(acc)\n",
    "\n",
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss, metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=1)\n",
    "model_name = f\"weights_{kargs['num_layers']}layers_{kargs['d_model']}d_model_{kargs['num_heads']}num_heads.h5\"\n",
    "checkpoint_path = os.path.join(DATA_OUT_PATH, model_name)\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Desktop\\github\\Study\\NLP\\06.text_generation\\result\\transformer_kor -- Folder already exists\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(checkpoint_dir) :\n",
    "    print(\"{} -- Folder already exists\".format(checkpoint_dir))\n",
    "else :\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder Created\".format(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167/167 [==============================] - ETA: 0s - loss: 1.3871 - accuracy: 0.8549\n",
      "Epoch 1: val_accuracy improved from -inf to 0.85283, saving model to c:\\Users\\user\\Desktop\\github\\Study\\NLP\\06.text_generation\\result\\transformer_kor\\weights_4layers_512d_model_8num_heads.h5\n",
      "167/167 [==============================] - 359s 2s/step - loss: 1.3871 - accuracy: 0.8549 - val_loss: 1.5321 - val_accuracy: 0.8528\n"
     ]
    }
   ],
   "source": [
    "cp_callback = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                        batch_size=BATCH_SIZE, epochs =EPOCHS, validation_split=VALID_SPLIT,\n",
    "                        callbacks=[es_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load Weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 11s 11s/step - loss: 1.9870 - accuracy: 0.8012\n"
     ]
    }
   ],
   "source": [
    "def load_model_with_little_train() :\n",
    "    EPOCH, BATCH_SIZE = 1, 64\n",
    "    load_model = Transformer(**kargs)\n",
    "    load_model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), loss=loss, metrics=[accuracy])\n",
    "    history = load_model.fit([index_inputs[:BATCH_SIZE], index_outputs[:BATCH_SIZE]], index_targets[:BATCH_SIZE], batch_size=BATCH_SIZE, epochs=EPOCH)\n",
    "    return load_model\n",
    "\n",
    "\n",
    "model_name = f\"weights_{kargs['num_layers']}layers_{kargs['d_model']}d_model_{kargs['num_heads']}num_heads_best.h5\"\n",
    "load_model = load_model_with_little_train()\n",
    "load_model.load_weights(os.path.join(DATA_OUT_PATH, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요\n"
     ]
    }
   ],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']\n",
    "\n",
    "text = \"안녕\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = load_model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저랑 놀아요\n"
     ]
    }
   ],
   "source": [
    "text = \"뭐하고 있어?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = load_model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저랑 놀아요\n"
     ]
    }
   ],
   "source": [
    "text = \"뭐하고 놀까?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = load_model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "충분히 힘들지 않았으면 좋겠어요\n"
     ]
    }
   ],
   "source": [
    "text = \"음.. 그럼 카톡할까?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = load_model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나쁜 사람이 있을 것 같아요\n"
     ]
    }
   ],
   "source": [
    "text = \"난 안힘든데?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = load_model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "그렇게 이야기네요\n"
     ]
    }
   ],
   "source": [
    "text = \"주변에 다 좋은 사람들 뿐인데?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = load_model.inference(test_index_inputs)\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlpproject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3310d3cabcfe43f301d4126367e060a82f3896ba0e1f05dc3836dac6c22dd9a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
